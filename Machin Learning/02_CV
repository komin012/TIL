## KFold

- training data를 k개로 나누어 돌아가면서 k-1개의 데이터를 학습시키고 나머지 한개로 테스트
- 그 중 가장 적합한 parameter를 찾아 test data에 적용 
- 코드
```python
from sklearn.model_selction import KFold
kfold = KFold(n_splits=5, shuffle=False)
# default : n_splits=5, shuffle=False
kfold.split(X_train)
```
- target 데이터의 품종이 차례대로 나열되어 있는 경우 shuffle = True로 주어야 편향되지 않음

## Stratified KFold
- 원본 데이터의 레이블 분포를 고려한 뒤 이 분포와 동일하게 학습과 검증데이터 세트를 분배
- 코드
```python
from sklearn.model_selection import StratifiedKFold
skfold = StratifiedKFold(n_splits=5, shuffle=False)
# default : n_splits=5, shuffle=False
skfold.split(X_train,y_train)
```

## cross-val-score()
- cv를 설정하면 학습/예측/평가를 한꺼번에 수행하게 해주는 함수
- estimator가 classifier이고, y가 다중클래스인 경우 Stratified KFold 사용
- 코드
```python
from sklearn.model_selection import cross_val_score
scores = cross_val_score(dt_clf, X, y, scoring='accuracy', cv=3)
np.mean(scores)
```

## GridSearchCV
- 하이퍼파라미터 지정해 최적의 파라미터 도출 가능
- 코드
```python
from sklearn.model_selection import GridSearchCV
paramas = {'max_depth':[1,2,3], 'min_sample_leaf':[2,3]}
grid = GridSearchCV(dt_clf, param_grid=params, cv=3, refit=True, return_train_score=True)
# refit : 최적의 파라미터를 찾은 뒤 해당 하이퍼 파라미터로 재학습 여부. default는 True
# return_train_score : cv_results_에 score 포함 여부. default는 False
grid.fit(X_train,y_train)

result = pd.DataFrame(grid.cv_results_)
grid.best_params_
grid.best_score_

best_dt = grid.best_estimator_
y_pred = best_dt.predict(X_test)
accuracy_score(y_test, y_pred)
```
