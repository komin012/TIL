# PCA(Principal Component Analysis, 주성분)
- 변수 간의 상관관계를 이용하여 대표하는 주성분을 추출해 차원을 축소하는 기법
- 기존 데이터의 정보 유실을 최소화함
- 가장 높은 분산을 가지는 데이터의 축(주성분)을 찾아 이 축으로 차원을 축소
    - 분산이 데이터의 특성을 가장 잘 나타내는 것으로 간주

## PCA를 통한 차원 축소
1. 가장 큰 데이터 변동성(Variance)을 기반으로 첫 번째 벡터 축을 생성
2. 두 번째 축은 이 벡터 축에 직각이 되는 벡터(직교 벡터)를 축으로 함
3. 세 번째 축은 다시 두 번째 축과 직각이 되는 벡터로 함
4. 이렇게 생성된 벡터 축에 원본 데이터를 투영<br>
=> 벡터 축의 개수만큼의 차원으로 원본 데이터가 차원 축소됨

## 선형대수 관점에서 PCA 해석
- 입력 데이터의 공분산 행렬이 고유벡터와 고유값으로 분해될 수 있으며 분해된 고유벡터를 이용해 입력 데이터를 선형 변환하는 방식
    - 고유벡터 : PCA 주성분 벡터, 입력 데이터 분산의 큰 방향
    - 고유값: 고유벡터의 크기이자 입력 데이터의 분산
- 선형 변환이란?
    - 특정벡터에 행렬 A를 곱해 새로운 벡터로 변환하는 것
    - 특정 벡터를 하나의 공간에서 다른 공간으로 투영하는 개념
    - 행렬을 바로 공간으로 가정하는 것으로, 행렬이 곧 선형변환임

※ 참고
- 공분산 행렬 : 여러 변수의 공분산을 포함하는 정방행렬
- 고유값 분해(eigen decomposition): 고유값(eigen value) 행렬과 고유벡터(eigen vector)행렬로 분해되는 행렬의 표현
    - $A=QΛQ^T$
        - (Q:고유벡터 행렬, Λ:고유값 행렬) 
- 고유벡터(eigen vector)
    - 행렬이 벡터에 작용하는 주축(pricipal axis)방향을 나타냄
    - 선형 변환이 일어난 후에도 방향이 변하지 않는 0이 아닌 벡터
    - 공분산행렬의 고유벡터는 데이터가 어떤 방향으로 분산되어 있는지를 나타내줌
- 고유값(eigen value)
    - 고유벡터 방향을 얼마만큼의 크기로 벡터공간이 늘려지는지 정도

## PCA 수행 순저
1. 입력 데이터의 공분산 행렬 생성
2. 공분산 행렬의 고유벡터와 고유값 계산
3. 고유값이 가장 큰 순을 K개(PCA 변환 차수만큼)만큼 고유벡터 추출
4. 고유값이 가장 큰 순으로 추출된 고유벡터를 이용해 새롭게 입력 데이터 변환