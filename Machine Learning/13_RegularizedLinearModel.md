# 규제 선형 모델

- 회귀모델은 적절히 데이터에 적합하면서도 회귀 계수가 기하급수적으로 커지는 것을 제어

- 선형모델의 RSS 최소화하는 비용함수의 한계점
    - 실제값과 예측값의 차이를 최소화하는 것만 고려함에 따라 학습 데이터에 지나치게 맞추게 되고 회귀계수가 쉽게 커짐
    - 이에 따라 변동성이 심해져서 테스트 데이터세트에서 예측 성능이 저하되기 쉬움
    
- 학습데이터 잔차 오류 최소화 + 회귀계수 크기 제어의 균형을 맞추도록 함<br>
$RSS(W) + \alpha*||W||_2^2$ 최소화
    - $\alpha=0$ : $W$가 커도 $\alpha*||W||_2^2$가 0이 되어 비용함수는 $min(RSS(W))$
    - $\alpha=\infty$ : $\alpha*||W||_2^2$가 무한대가 되어 비용함수는 $W$를 0에 가깝게 최소화해야 함

## 규제선형모델 유형
### 1. 릿지 회귀(Ridge Regression)
- L2 규제 : 가중치의 제곱합에 패널티를 부과
- 과적합을 피하고 일반화 성능을 강화하는 방법
- $L(\beta) = min(RSS(W))+\lambda\sum\beta^2_j$
- 특징 
    - 변수 간 상관관계가 높은 상황(다중공선성)에서 좋은 예측 성능
    - 회귀계수의 크기가 큰 변수를 우선적으로 줄이는 경향이 있음
    - 변수 선택 불가능

### 2. 라쏘 회귀(Lasso Regression)
- L1 규제 : 가중치 절대값의 합에 패널티를 부과
- $RSS(W) + \lambda\sum|\beta_j|$
- 특징
    - 회귀계수 일부가 0이 되어 변수 선택 기법으로 활용
    - 변수 간 상관관계가 높은 상황에서 Ridge에 비해 상대적으로 예측성능이 떨어짐

### 3. 엘라스틱넷 회귀(ElasticNet Regression)
- L1과 L2 규제를 결합한 회귀
- 
$RSS(W)+\alpha_2||W||^2_2+\alpha_1||W||_1$
- 라쏘회귀의 단점을 완화하기 위해 L2 규제를 라쏘회귀에 추가한 것
- 수행시간이 오래걸리는 단점이 있음